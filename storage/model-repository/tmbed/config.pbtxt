name: "tmbed"
platform: "ensemble"
max_batch_size: 16

input [
  {
    name: "input"
    data_type: TYPE_FP32
    dims: [ -1, 1024 ]  # ProtT5 embeddings sequence
  },
  {
    name: "mask"
    data_type: TYPE_FP32
    dims: [ -1 ]  # Attention mask
  }
]



output [
  {
    name: "output_0"
    data_type: TYPE_FP32
    dims: [ -1, -1 ]  # Variable output dimensions
  },
  {
    name: "output_1"
    data_type: TYPE_FP32
    dims: [ -1, -1 ]  # Variable output dimensions
  },
  {
    name: "output_2"
    data_type: TYPE_FP32
    dims: [ -1, -1 ]  # Variable output dimensions
  },
  {
    name: "output_3"
    data_type: TYPE_FP32
    dims: [ -1, -1 ]  # Variable output dimensions
  },
  {
    name: "output_4"
    data_type: TYPE_FP32
    dims: [ -1, -1 ]  # Variable output dimensions
  }
]

ensemble_scheduling {
  step: [
    {
      model_name: "_tmbed_cv0"
      model_version: -1
      input_map {
        key: "input_embedding"
        value: "ensemble_input"
      }
      output_map {
        key: "output_logits"
        value: "output_0"
      }
    },
    {
      model_name: "_tmbed_cv1"
      model_version: -1
      input_map {
        key: "input_embedding"
        value: "ensemble_input"
      }
      output_map {
        key: "output_logits"
        value: "output_1"
      }
    },
    {
      model_name: "_tmbed_cv2"
      model_version: -1
      input_map {
        key: "input_embedding"
        value: "ensemble_input"
      }
      output_map {
        key: "output_logits"
        value: "output_2"
      }
    },
    {
      model_name: "_tmbed_cv3"
      model_version: -1
      input_map {
        key: "input_embedding"
        value: "ensemble_input"
      }
      output_map {
        key: "output_logits"
        value: "output_3"
      }
    },
    {
      model_name: "_tmbed_cv4"
      model_version: -1
      input_map {
        key: "input_embedding"
        value: "ensemble_input"
      }
      output_map {
        key: "output_logits"
        value: "output_4"
      }
    }
  ]
}