services:
  embeddings-db:
    image: postgres:15
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "${POSTGRES_PORT}:5432"
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}" ]
      interval: 5s
      timeout: 5s
      retries: 5

  redis-jobs:
    image: redis:alpine
    ports:
      - "${REDIS_JOBS_PORT}:6379"
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 5s
      timeout: 5s
      retries: 5

  redis-commander:
    image: rediscommander/redis-commander:latest
    environment:
      - REDIS_HOSTS=local:redis-jobs:6379
    ports:
      - "8081:8081"
    depends_on:
      - redis-jobs
    restart: unless-stopped

  seaweedfs-master:
    image: chrislusf/seaweedfs
    command: "master -ip=seaweedfs-master -port=9333 -port.grpc=19333"
    networks:
      - seaweedfs-network

  seaweedfs-volume:
    image: chrislusf/seaweedfs
    command: 'volume -mserver="seaweedfs-master:9333" -port=8080 -port.grpc=18080 -ip=seaweedfs-volume'
    volumes:
      - seaweedfs_data:/data
    depends_on:
      - seaweedfs-master
    networks:
      - seaweedfs-network

  seaweedfs-filer:
    image: chrislusf/seaweedfs
    ports:
      - "${SEAWEEDFS_FILER_PORT}:8888"
    command: 'filer -master="seaweedfs-master:9333" -port=8888 -port.grpc=18888 -ip=seaweedfs-filer'
    depends_on:
      - seaweedfs-master
      - seaweedfs-volume
    networks:
      - seaweedfs-network
    healthcheck:
      test: [ "CMD", "wget", "--spider", "--quiet", "-Y", "off", "http://seaweedfs-filer:8888/" ]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 20s

  triton-model-init:
    build:
      context: ./storage/model-repository
      dockerfile: Dockerfile.init
    volumes:
      - triton_models:/models
    environment:
      - MODEL_REPOSITORY_PATH=/models
      - MODEL_DOWNLOADS=${MODEL_DOWNLOADS:-}

  triton:
    build:
      context: ./storage/model-repository
      dockerfile: Dockerfile.triton
    deploy:
      resources:
        limits:
          memory: 24G  # ESM2-T36 (3B params) requires ~14-22GB for inference
        reservations:
          memory: 16G
    command: >
      tritonserver
      --model-repository=/models
      --model-control-mode=explicit
      --load-model=prot_t5_pipeline
      --load-model=esm2_t33_pipeline
      --load-model=esm2_t36_pipeline
      --load-model=prott5_sec
      --load-model=prott5_cons
      --load-model=bind_embed
      --load-model=seth
      --load-model=tmbed
      --load-model=light_attention_subcell
      --load-model=light_attention_membrane
      --load-model=vespag
      --disable-auto-complete-config
      --log-verbose=1
    ports:
      - "8000:8000"  # HTTP
      - "8001:8001"  # gRPC
      - "8002:8002"  # Metrics
    volumes:
      - ./storage/model-repository:/models:ro
    depends_on:
      triton-model-init:
        condition: service_completed_successfully
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/v2/health/ready" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${EMBEDDINGS_DATA_DIR}
  seaweedfs_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${FILES_DATA_DIR}
  triton_models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${MODEL_REPOSITORY_PATH:-./storage/model-repository}

networks:
  seaweedfs-network:
    driver: bridge
